{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_descrition = \"This dataset includes 1350 images of objects of varied counts, 150 images for each count between 2 and 10. It consists of images automatically sourced from multiple sources, including the COCO Dataset, Conceptual 12M, YFCC100M, and SBU Captions Dataset. In addition, due to the fact that images with large counts (i.e., nine and ten) are scarce, to compose 150 images for each count, we also manually collect some images from the Internet. Each text image pair is manually checked and the captions are revised to get rid of grammar errors and noisy information. Images are also manually checked to avoid duplication. This dataset can be used to train to improve or evaluate a visual language model's object counting accuracy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /Users/susu/miniconda3/envs/clipcount/lib/python3.8/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/susu/miniconda3/envs/clipcount/lib/python3.8/site-packages (from torch) (4.11.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in /Users/susu/miniconda3/envs/clipcount/lib/python3.8/site-packages (from torch) (2024.3.1)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl (150.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_x86_64.whl (14 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.5 jinja2-3.1.4 mpmath-1.3.0 networkx-3.1 sympy-1.12.1 torch-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "costum_data = torch.load(\"../my_eval_data_all.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "costum_data_json = []\n",
    "for obj in costum_data:\n",
    "    for count in costum_data[obj]:\n",
    "        for sample in costum_data[obj][count]:\n",
    "            costum_data_json.append(\n",
    "                {\n",
    "                    \"object\":obj,\n",
    "                    \"count\":count,\n",
    "                    \"url\":sample[\"url\"]\n",
    "                }\n",
    "            ) \n",
    "import json\n",
    "with open(\"my_eval_data_all.json\", 'w') as json_file:\n",
    "    json.dump(costum_data_json, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susu/miniconda3/envs/clipcount/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 360 examples [00:00, 12638.63 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 183.49ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruisu516/ObjectCount/commit/07e00cd50856b12a03d084dd2bec0fcc26dcd9f7', commit_message='Upload dataset', commit_description='', oid='07e00cd50856b12a03d084dd2bec0fcc26dcd9f7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from huggingface_hub import HfApi,notebook_login\n",
    "exited_reviewed_file = \"./my_eval_data_all.json\"\n",
    "dataset = load_dataset('json', data_files=exited_reviewed_file)\n",
    "\n",
    "dataset.push_to_hub(\"ruisu516/ObjectCount\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susu/miniconda3/envs/clipcount/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 231.97ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruisu516/DiverseCount/commit/7e7ba3d0efd64b7b0cdd27cbb2ed6602a688428e', commit_message='Upload dataset', commit_description='', oid='7e7ba3d0efd64b7b0cdd27cbb2ed6602a688428e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from huggingface_hub import HfApi,notebook_login\n",
    "exited_reviewed_file = \"/Users/susu/Library/CloudStorage/OneDrive-Personal/Wisc/clip_count_continued/CLIP_Counting/online_data_9_class_final/online_data_class_9_all_reviewed.json\"\n",
    "dataset = load_dataset('json', data_files=exited_reviewed_file)\n",
    "\n",
    "dataset.push_to_hub(\"ruisu516/DiverseCount\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HfApi' object has no attribute 'login'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Login to Hugging Face (this will require your token)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# You can retrieve your token from Hugging Face's website under your account settings\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# Login to Hugging Face\u001b[39;00m\n\u001b[1;32m     14\u001b[0m api \u001b[39m=\u001b[39m HfApi()\n\u001b[0;32m---> 15\u001b[0m api\u001b[39m.\u001b[39;49mlogin(username\u001b[39m=\u001b[39musername, token\u001b[39m=\u001b[39mtoken)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Create a new dataset repository on Hugging Face Hub\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Replace 'your_dataset_name' with your desired repository name\u001b[39;00m\n\u001b[1;32m     19\u001b[0m repo_url \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mcreate_repo(repo_id\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDiverseCount\u001b[39m\u001b[39m\"\u001b[39m, repo_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HfApi' object has no attribute 'login'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from huggingface_hub import HfApi,notebook_login\n",
    "\n",
    "# Load your dataset from a JSON file\n",
    "username = \"ruisu516\"\n",
    "token = \"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\"\n",
    "exited_reviewed_file = \"/Users/susu/Library/CloudStorage/OneDrive-Personal/Wisc/clip_count_continued/CLIP_Counting/online_data_9_class_final/online_data_class_9_all_reviewed.json\"\n",
    "\n",
    "dataset = load_dataset('json', data_files=exited_reviewed_file)\n",
    "\n",
    "# Login to Hugging Face (this will require your token)\n",
    "# You can retrieve your token from Hugging Face's website under your account settings\n",
    "# Login to Hugging Face\n",
    "api = HfApi()\n",
    "api.login(username=username, token=token)\n",
    "\n",
    "# Create a new dataset repository on Hugging Face Hub\n",
    "# Replace 'your_dataset_name' with your desired repository name\n",
    "repo_url = api.create_repo(repo_id=\"DiverseCount\", repo_type=\"dataset\", exist_ok=True)\n",
    "\n",
    "# Push your dataset to the hub\n",
    "dataset.push_to_hub(\"ruisu516/DiverseCount\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susu/miniconda3/envs/clipcount/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/clipcount/lib/python3.8/site-packages/huggingface_hub/_login.py:237\u001b[0m, in \u001b[0;36mnotebook_login\u001b[0;34m(new_session, write_permission)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mipywidgets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwidgets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mwidgets\u001b[39;00m  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m display  \u001b[39m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywidgets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m HfApi,notebook_login\n\u001b[0;32m----> 2\u001b[0m notebook_login()\n",
      "File \u001b[0;32m~/miniconda3/envs/clipcount/lib/python3.8/site-packages/huggingface_hub/_login.py:240\u001b[0m, in \u001b[0;36mnotebook_login\u001b[0;34m(new_session, write_permission)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m display  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    241\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `notebook_login` function can only be used in a notebook (Jupyter or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_session \u001b[39mand\u001b[39;00m _current_token_okay(write_permission\u001b[39m=\u001b[39mwrite_permission):\n\u001b[1;32m    245\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUser is already logged in.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi,notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipcount",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
