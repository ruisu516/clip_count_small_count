{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title save online training dataset (json to pth) (4 class)\n",
    "\n",
    "\n",
    "SAMPLE_SIZE_PER_CLASS = 58\n",
    "num_classes = 4\n",
    "num_word_to_number = {\n",
    "        \"two\":2,\n",
    "        \"three\":3,\n",
    "        \"four\":4,\n",
    "        \"five\":5\n",
    "    }\n",
    "num_class_to_num_word = {\n",
    "        2:\"two\",\n",
    "        3:\"three\",\n",
    "        4:\"four\",\n",
    "        5:\"five\"\n",
    "    }\n",
    "def create_online_dataset_texts(\n",
    "        train_set,\n",
    "        model,\n",
    "        processor,\n",
    "        device=\"cuda\",\n",
    "        num_class = 4,\n",
    "        logits_bound=None\n",
    "):\n",
    "    print(\"upper bound\", num_class + 1)\n",
    "    online_dataset=[]\n",
    "    sample_count_tracking = {}\n",
    "    # for n in range(2,num_class + 2):\n",
    "    #     sample_count_tracking[n] = 0\n",
    "\n",
    "    logits = []\n",
    "    for i, sample in tqdm(enumerate(train_set)):\n",
    "        if sample[\"number\"] > num_class + 1:\n",
    "            continue\n",
    "        # if sample_count_tracking[sample[\"number\"]] >= SAMPLE_SIZE_PER_CLASS:\n",
    "        #     continue\n",
    "\n",
    "        try:\n",
    "            image = Image.open(requests.get(sample[\"image_url\"], stream=True,timeout=10).raw)\n",
    "        except Timeout:\n",
    "            print(\"timeout\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "        target_obj_text = sample['target']\n",
    "        target_obj_with_context_text = sample['target_context'].replace(num_class_to_num_word[sample['number']],\"\")\n",
    "        target_obj_aug_text = [f\"{num} {sample['target']}\" for num in numer_words[:num_classes]]\n",
    "        target_obj_aug_with_context_text = [sample['target_context'].replace(num_class_to_num_word[sample['number']],num) for num in numer_words[:num_classes]]\n",
    "        # target_obj_aug_with_context_text,target_obj_text,target_obj_with_context_text,target_obj_aug_text = sentence_augmentation(sample[\"text\"])\n",
    "\n",
    "        pixel_values=processor(text=None, images=image, return_tensors=\"pt\", padding=True)[\"pixel_values\"] # torch.Size([1, 3, 224, 224])\n",
    "\n",
    "        image_embeds = get_image_embeds(\n",
    "            model=model,\n",
    "            pixel_values=pixel_values,\n",
    "            device=device,\n",
    "        )\n",
    "        target_embeds = text2embedding(target_obj_with_context_text,model,processor,device,True)\n",
    "\n",
    "\n",
    "        online_dataset.append(\n",
    "            {\n",
    "                \"gt_count\":sample['number'],\n",
    "                \"target_obj_text\":target_obj_text,\n",
    "                \"target_obj_aug_text\":target_obj_aug_text,\n",
    "                \"target_obj_with_context_text\":target_obj_with_context_text,\n",
    "                \"target_obj_aug_with_context_text\":target_obj_aug_with_context_text,\n",
    "                \"image_embeds\":image_embeds.detach().cpu(),\n",
    "            }\n",
    "        )\n",
    "        # sample_count_tracking[sample[\"number\"]] += 1\n",
    "        del pixel_values, image_embeds\n",
    "    # print(sample_count_tracking)\n",
    "    return online_dataset\n",
    "\n",
    "\n",
    "def online_data_save_name(model_name,num_class,texts,mode,size,seed,end=\"\"):\n",
    "    # save_name = f\"countbench_{model_name}_{num_class}class_texts{texts}_{SAMPLE_SIZE_PER_CLASS}samples_per_class.pth\"\n",
    "    save_name = f\"online_data_{model_name}_{num_class}class_{mode}{size}_texts{texts}_seed{seed}_{end}.pth\"\n",
    "    print(f\"Save name: {save_name}\")\n",
    "    return save_name\n",
    "\n",
    "device=\"cuda\"\n",
    "use_arabic=False\n",
    "if use_arabic:\n",
    "    name_appendix = \"_arabic\"\n",
    "    numer_words = ARABIC_NUMBER_WORDS\n",
    "else:\n",
    "    name_appendix = \"\"\n",
    "    numer_words = NUMBER_WORDS\n",
    "\n",
    "save_root_folder=\"./online_data/reviewed_class2345/\"\n",
    "texts=True\n",
    "\n",
    "for filename in os.listdir(save_root_folder):\n",
    "    if filename.endswith('.json'): \n",
    "        with open(os.path.join(save_root_folder,filename),\"r\") as f:\n",
    "            train_set = json.load(f)\n",
    "    print(len(train_set),filename)\n",
    "    mode = \"train\" if \"train\" in filename else \"val\"\n",
    "    seed = int(filename.split(\"seed\")[-1].split(\".\")[0])\n",
    "\n",
    "    for idx, model_name in  enumerate([\"clip-vit-large-patch14\",\"clip-vit-base-patch32\",\"clip-vit-base-patch16\"]): #,\"clip-vit-large-patch14\"\n",
    "        model = CLIPModel.from_pretrained(f\"openai/{model_name}\").to(device)\n",
    "        model.requires_grad=False\n",
    "        processor = CLIPProcessor.from_pretrained(f\"openai/{model_name}\")\n",
    "\n",
    "\n",
    "        online_dataset = create_online_dataset_texts(\n",
    "                train_set,\n",
    "                model,\n",
    "                processor,\n",
    "                device=device,\n",
    "                num_class = 4,\n",
    "        )\n",
    "        print(len(online_dataset))\n",
    "        torch.save(\n",
    "            online_dataset,\n",
    "            os.path.join(save_root_folder,online_data_save_name(model_name,4,texts,mode,len(train_set),seed,end=name_appendix))\n",
    "        )\n",
    "        # del online_dataset"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
